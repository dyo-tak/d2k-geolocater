{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IcXyP1aPGzDP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dyota\\anaconda3\\envs\\d2k\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from text_result import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-joY1auZHxHI"
   },
   "outputs": [],
   "source": [
    "hub_model = 'k4tel/geo-bert-multilingual'\n",
    "base_model = \"bert-base-multilingual-cased\"\n",
    "use_pipeline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOvPAouwIZyk",
    "outputId": "b7a1f77c-05c1-470b-cfca-a19697474ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL\tInitializing BERT Regression model for 5 outcome(s)\n",
      "MODEL\tText features:\tNON-GEO + GEO-ONLY\n",
      "MODEL\tCoordinates:\t10\n",
      "MODEL\tWeights:\t5\n",
      "MODEL\tCovariances:\t5\tmatrix type:\tspher\n",
      "MODEL\tOriginal model to load:\tbert-base-multilingual-cased\n",
      "MODEL\tKey feature \tNON-GEO outputs:\t20\n",
      "MODEL\tMinor feature\tGEO-ONLY outputs:\t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 625/625 [00:00<?, ?B/s] \n",
      "c:\\Users\\dyota\\anaconda3\\envs\\d2k\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dyota\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.25MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<?, ?B/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.70MB/s]\n",
      "c:\\Users\\dyota\\anaconda3\\envs\\d2k\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dyota\\.cache\\huggingface\\hub\\models--k4tel--geo-bert-multilingual. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 125kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 412/412 [00:00<00:00, 413kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD\tLoading HF model from k4tel/geo-bert-multilingual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 781/781 [00:00<?, ?B/s] \n",
      "pytorch_model.bin: 100%|██████████| 712M/712M [05:21<00:00, 2.21MB/s] \n"
     ]
    }
   ],
   "source": [
    "model_wrapper = load_model(base_model, hub_model, use_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "URbyQtMnIV92"
   },
   "outputs": [],
   "source": [
    "text =  \"FBI and CIA are the best intelligence agencies in the world. They are responsible for the security of the country\"\n",
    "filter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6quCv7dbJx7M",
    "outputId": "3f785699-069b-4cb5-d184-e4383d6feed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT\tFiltering text: FBI and CIA are the best intelligence agencies in the world. They are responsible for the security of the country\n",
      "RESULT\tPost-processing raw model outputs: tensor([[ -61.4407,   24.2054,  -80.5373,   33.1193,  -82.0744,   32.0352,\n",
      "           17.7214,   32.5449,  -77.0794,    6.7262,  -13.8213,    5.1097,\n",
      "            2.7705,  -14.2502,  -14.4791,   -0.3295,   49.7789,   -4.5694,\n",
      "          155.1785, -109.4892]])\n",
      "RESULT\tSorting all outputs for 5 outcomes by probabilistic weights\n",
      "RESULT\t2 significant prediction outcome(s):\n",
      "\tOut 1\t91.21%\t-\tlon: -80.53726959228516  lat: 33.11930847167969\n",
      "\tOut 2\t8.79%\t-\tlon: -82.07439422607422  lat: 32.03517150878906\n"
     ]
    }
   ],
   "source": [
    "result = text_prediction(model_wrapper, text, use_pipeline, filter)\n",
    "\n",
    "ind = np.argwhere(np.round(result.weights[0, :] * 100, 2) > 0)\n",
    "significant = result.means[0, ind].reshape(-1, 2)\n",
    "weights = result.weights[0, ind].flatten()\n",
    "\n",
    "sig_weights = weights[weights > 0]\n",
    "\n",
    "print(f\"RESULT\\t{len(sig_weights)} significant prediction outcome(s):\")\n",
    "for i in range(len(sig_weights)):\n",
    "    point = f\"lon: {'  lat: '.join(map(str, significant[i]))}\"\n",
    "    weight = str(np.round(sig_weights[i] * 100, 2))\n",
    "    print(f\"\\tOut {i + 1}\\t{weight}%\\t-\\t{point}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
